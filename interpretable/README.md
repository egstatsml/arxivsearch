# interpretable
Click on title for link to paper
## 13-12-2019

main_author|title|update_date|publish_date
---|---|---|---
Santi Seguí|[WCE Polyp Detection with Triplet based Embeddings](http://arxiv.org/abs/1912.04643v1)|2019-12-10 11:08:45+00:00|10-12-2019
Narges Razavian|[Graph Neural Network on Electronic Health Records for Predicting   Alzheimer's Disease](http://arxiv.org/abs/1912.03761v1)|2019-12-08 21:06:38+00:00|08-12-2019
Suvrit Sra|[Why ADAM Beats SGD for Attention Models](http://arxiv.org/abs/1912.03194v1)|2019-12-06 15:58:29+00:00|06-12-2019
Roman Klinger|[GoodNewsEveryone: A Corpus of News Headlines Annotated with Emotions,   Semantic Roles, and Reader Perception](http://arxiv.org/abs/1912.03184v1)|2019-12-06 15:30:58+00:00|06-12-2019
Eduardo Soares|[Towards Explainable Deep Neural Networks (xDNN)](http://arxiv.org/abs/1912.02523v1)|2019-12-05 12:01:15+00:00|05-12-2019

## 06-12-2019

main_author|title|update_date|publish_date
---|---|---|---
Dan Goldwasser|[An Anomaly Contribution Explainer for Cyber-Security Applications](http://arxiv.org/abs/1912.00314v1)|2019-12-01 04:16:12+00:00|01-12-2019
Changsheng Xu|[Time-Guided High-Order Attention Model of Longitudinal Heterogeneous   Healthcare Data](http://arxiv.org/abs/1912.00773v1)|2019-11-28 03:15:24+00:00|28-11-2019
Aad van Moorsel|[The relationship between trust in AI and trustworthy machine learning   technologies](http://arxiv.org/abs/1912.00782v2)|2019-12-03 11:59:43+00:00|27-11-2019

## 29-11-2019

main_author|title|update_date|publish_date
---|---|---|---
Travis LaCroix|[Biology and Compositionality: Empirical Considerations for   Emergent-Communication Protocols](http://arxiv.org/abs/1911.11668v1)|2019-11-26 16:07:44+00:00|26-11-2019

## 22-11-2019

title|publish_date|main_author
---|---|---
No papers found this week|22-11-2019|  

## 21-11-2019

title|publish_date|main_author
---|---|---
No papers found this week|21-11-2019|  

## 21-11-2019

main_author|title|update_date|publish_date
---|---|---|---
Ehud Reiter|[Natural Language Generation Challenges for Explainable AI](http://arxiv.org/abs/1911.08794v1)|2019-11-20 09:52:23+00:00|20-11-2019
Xiaodan Liang|[Vision-Language Navigation with Self-Supervised Auxiliary Reasoning   Tasks](http://arxiv.org/abs/1911.07883v1)|2019-11-18 19:17:57+00:00|18-11-2019
Maithilee Kunda|[Modeling Gestalt Visual Reasoning on the Raven's Progressive Matrices   Intelligence Test Using Generative Image Inpainting Techniques](http://arxiv.org/abs/1911.07736v1)|2019-11-18 16:16:55+00:00|18-11-2019
Ziyan Wu|[Learning Similarity Attention](http://arxiv.org/abs/1911.07381v1)|2019-11-18 00:46:40+00:00|18-11-2019
Jimeng Sun|[CASTER: Predicting Drug Interactions with Chemical Substructure   Representation](http://arxiv.org/abs/1911.06446v2)|2019-11-20 03:55:01+00:00|15-11-2019
Sambuddha Ghosal|[Deep Generative Models Strike Back! Improving Understanding and   Evaluation in Light of Unmet Expectations for OoD Data](http://arxiv.org/abs/1911.04699v1)|2019-11-12 06:41:22+00:00|12-11-2019
Weisi Guo|[Explainable Artificial Intelligence (XAI) for 6G: Improving Trust   between Human and Machine](http://arxiv.org/abs/1911.04542v2)|2019-11-19 21:37:33+00:00|11-11-2019
M. W. Spratling|[Explaining Away Results in Accurate and Tolerant Template Matching](http://arxiv.org/abs/1911.04169v1)|2019-11-11 10:44:42+00:00|11-11-2019
H. Andrew Schwartz|[Correcting Sociodemographic Selection Biases for Accurate Population   Prediction from Social Media](http://arxiv.org/abs/1911.03855v1)|2019-11-10 05:13:29+00:00|10-11-2019
Xiang Ren|[Towards Hierarchical Importance Attribution: Explaining Compositional   Semantics for Neural Sequence Models](http://arxiv.org/abs/1911.06194v1)|2019-11-08 03:25:04+00:00|08-11-2019
Dongwon Lee|[Why X rather than Y? Explaining Neural Model' Predictions by Generating   Intervention Counterfactual Samples](http://arxiv.org/abs/1911.02042v1)|2019-11-05 19:06:29+00:00|05-11-2019
Wei Fan|[Explaining the Predictions of Any Image Classifier via Decision Trees](http://arxiv.org/abs/1911.01058v1)|2019-11-04 07:31:30+00:00|04-11-2019
Bowen Zhou|[Select, Answer and Explain: Interpretable Multi-hop Reading   Comprehension over Multiple Documents](http://arxiv.org/abs/1911.00484v2)|2019-11-04 01:45:25+00:00|01-11-2019
Stéphane Dupont|[Can adversarial training learn image captioning ?](http://arxiv.org/abs/1910.14609v1)|2019-10-31 16:59:14+00:00|31-10-2019
Isao Echizen|[Use of a Capsule Network to Detect Fake Images and Videos](http://arxiv.org/abs/1910.12467v2)|2019-10-29 14:30:58+00:00|28-10-2019
Walter Karlen|[CXPlain: Causal Explanations for Model Interpretation under Uncertainty](http://arxiv.org/abs/1910.12336v1)|2019-10-27 19:59:18+00:00|27-10-2019
Vishaal Udandarao|[Memeify: A Large-Scale Meme Generation System](http://arxiv.org/abs/1910.12279v1)|2019-10-27 15:13:26+00:00|27-10-2019
Tetusya Takiguchi|[Assisting human experts in the interpretation of their visual process: A   case study on assessing copper surface adhesive potency](http://arxiv.org/abs/1910.11033v1)|2019-10-24 11:23:58+00:00|24-10-2019
Sebastian Lapuschkin|[Towards best practice in explaining neural network decisions with LRP](http://arxiv.org/abs/1910.09840v1)|2019-10-22 08:58:54+00:00|22-10-2019
Pushmeet Kohli|[An Alternative Surrogate Loss for PGD-based Adversarial Testing](http://arxiv.org/abs/1910.09338v1)|2019-10-21 13:08:54+00:00|21-10-2019
Barbara Hammer|[Recovering Localized Adversarial Attacks](http://arxiv.org/abs/1910.09239v1)|2019-10-21 09:53:44+00:00|21-10-2019
Takayuki Okatani|[Analysis and a Solution of Momentarily Missed Detection for Anchor-based   Object Detectors](http://arxiv.org/abs/1910.09212v1)|2019-10-21 08:57:37+00:00|21-10-2019
Xinhong Hei|[A game method for improving the interpretability of convolution neural   network](http://arxiv.org/abs/1910.09090v1)|2019-10-21 00:32:40+00:00|21-10-2019
Alexander Wong|[Do Explanations Reflect Decisions? A Machine-centric Strategy to   Quantify the Performance of Explainability Algorithms](http://arxiv.org/abs/1910.07387v2)|2019-10-29 21:14:22+00:00|16-10-2019
Saurabh Johri|[Counterfactual diagnosis](http://arxiv.org/abs/1910.06772v2)|2019-10-28 23:55:42+00:00|15-10-2019
Colin Rowat|[Asymmetric Shapley values: incorporating causal knowledge into   model-agnostic explainability](http://arxiv.org/abs/1910.06358v1)|2019-10-14 18:08:32+00:00|14-10-2019
Sebastian Gehrmann|[exBERT: A Visual Analysis Tool to Explore Learned Representations in   Transformers Models](http://arxiv.org/abs/1910.05276v1)|2019-10-11 16:10:55+00:00|11-10-2019
Phil Blunsom|[Can I Trust the Explainer? Verifying Post-hoc Explanatory Methods](http://arxiv.org/abs/1910.02065v2)|2019-10-09 14:58:47+00:00|04-10-2019
Gilles Tredan|[The Bouncer Problem: Challenges to Remote Explainability](http://arxiv.org/abs/1910.01432v1)|2019-10-03 12:54:00+00:00|03-10-2019
Ali Mirjalili|[Silas: High Performance, Explainable and Verifiable Machine Learning](http://arxiv.org/abs/1910.01382v1)|2019-10-03 10:17:50+00:00|03-10-2019
Junpei Komiyama|[A Robust Transferable Deep Learning Framework for Cross-sectional   Investment Strategy](http://arxiv.org/abs/1910.01491v1)|2019-10-02 11:02:57+00:00|02-10-2019
Hermann Ney|[When and Why is Document-level Context Useful in Neural Machine   Translation?](http://arxiv.org/abs/1910.00294v1)|2019-10-01 10:40:26+00:00|01-10-2019
María Rodríguez Martínez|[MonoNet: Towards Interpretable Models by Learning Monotonic Features](http://arxiv.org/abs/1909.13611v1)|2019-09-30 12:02:16+00:00|30-09-2019
Jung Hoon Lee|[Library network, a possible path to explainable neural networks](http://arxiv.org/abs/1909.13360v2)|2019-11-12 16:12:46+00:00|29-09-2019
Taiji Suzuki|[Compression based bound for non-compressed network: unified   generalization error analysis of large compressible deep neural network](http://arxiv.org/abs/1909.11274v2)|2019-09-26 05:40:09+00:00|25-09-2019
Mohan Sridharan|[Non-monotonic Logical Reasoning Guiding Deep Learning for Explainable   Visual Question Answering](http://arxiv.org/abs/1909.10650v1)|2019-09-23 23:34:32+00:00|23-09-2019
Miguel Navascues|[Quantum Inflation: A General Approach to Quantum Causal Compatibility](http://arxiv.org/abs/1909.10519v1)|2019-09-23 18:00:00+00:00|23-09-2019
Liang Lin|[Explainable High-order Visual Question Reasoning: A New Benchmark and   Knowledge-routed Network](http://arxiv.org/abs/1909.10128v1)|2019-09-23 02:38:56+00:00|23-09-2019

   