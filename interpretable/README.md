# interpretable
Click on title for link to paper
## 21-02-2020

main_author|title|update_date|publish_date
---|---|---|---
David Page|[CAUSE: Learning Granger Causality from Event Sequences using Attribution   Methods](http://arxiv.org/abs/2002.07906v1)|2020-02-18 22:21:11+00:00|18-02-2020
Wei Fan|[A Modified Perturbed Sampling Method for Local Interpretable   Model-agnostic Explanation](http://arxiv.org/abs/2002.07434v1)|2020-02-18 09:03:10+00:00|18-02-2020
Isabel Valera|[Algorithmic Recourse: from Counterfactual Explanations to Interventions](http://arxiv.org/abs/2002.06278v1)|2020-02-14 22:49:42+00:00|14-02-2020
Kyle Richardson|[Transformers as Soft Reasoners over Language](http://arxiv.org/abs/2002.05867v1)|2020-02-14 04:23:28+00:00|14-02-2020

## 14-02-2020

main_author|title|update_date|publish_date
---|---|---|---
Min Chen|[HypoML: Visual Analysis for Hypothesis-based Evaluation of Machine   Learning Models](http://arxiv.org/abs/2002.05271v1)|2020-02-12 23:03:44+00:00|12-02-2020
U. Rajendra Acharya|[HAN-ECG: An Interpretable Atrial Fibrillation Detection Model Using   Hierarchical Attention Networks](http://arxiv.org/abs/2002.05262v1)|2020-02-12 22:23:06+00:00|12-02-2020
Daniel C. Elton|[Self-explainability as an alternative to interpretability for judging   the trustworthiness of artificial intelligences](http://arxiv.org/abs/2002.05149v1)|2020-02-12 18:50:11+00:00|12-02-2020
Barbara Hammer|[Convex Density Constraints for Computing Plausible Counterfactual   Explanations](http://arxiv.org/abs/2002.04862v1)|2020-02-12 09:23:42+00:00|12-02-2020
Shixia Liu|[OoDAnalyzer: Interactive Analysis of Out-of-Distribution Samples](http://arxiv.org/abs/2002.03103v1)|2020-02-08 06:58:33+00:00|08-02-2020
Johan Bollen|[Depressed individuals express more distorted thinking on social media](http://arxiv.org/abs/2002.02800v1)|2020-02-07 14:18:53+00:00|07-02-2020

## 07-02-2020

main_author|title|update_date|publish_date
---|---|---|---
Mark Przybocki|[Four Principles of Explainable AI as Applied to Biometrics and Facial   Forensic Algorithms](http://arxiv.org/abs/2002.01014v1)|2020-02-03 21:03:20+00:00|03-02-2020
Anca D. Dragan|[Quantifying Hypothesis Space Misspecification in Learning from   Human-Robot Demonstrations and Physical Corrections](http://arxiv.org/abs/2002.00941v1)|2020-02-03 18:59:23+00:00|03-02-2020
Noah A. Smith|[Citation Text Generation](http://arxiv.org/abs/2002.00317v1)|2020-02-02 03:54:47+00:00|02-02-2020

## 31-01-2020

main_author|title|update_date|publish_date
---|---|---|---
Frank Vetere|[Distal Explanations for Explainable Reinforcement Learning Agents](http://arxiv.org/abs/2001.10284v1)|2020-01-28 11:57:38+00:00|28-01-2020
Matthias Dehmer|[Explainable Artificial Intelligence and Machine Learning: A reality   rooted perspective](http://arxiv.org/abs/2001.09464v1)|2020-01-26 15:09:45+00:00|26-01-2020
Klaus Mueller|[Explainable Active Learning (XAL): An Empirical Study of How Local   Explanations Impact Annotator Experience](http://arxiv.org/abs/2001.09219v1)|2020-01-24 22:52:18+00:00|24-01-2020

## 24-01-2020

main_author|title|update_date|publish_date
---|---|---|---
Masayoshi Tomizuka|[Interpretable End-to-end Urban Autonomous Driving with Latent Deep   Reinforcement Learning](http://arxiv.org/abs/2001.08726v1)|2020-01-23 18:36:35+00:00|23-01-2020
Kwan-Liu Ma|[Visual Summary of Value-level Feature Attribution in Prediction Classes   with Recurrent Neural Networks](http://arxiv.org/abs/2001.08379v1)|2020-01-23 05:38:30+00:00|23-01-2020
Xintian Han|[Explaining Data-Driven Decisions made by AI Systems: The Counterfactual   Approach](http://arxiv.org/abs/2001.07417v1)|2020-01-21 09:58:58+00:00|21-01-2020
Junichi Kuwata|[A point-wise linear model reveals reasons for 30-day readmission of   heart failure patients](http://arxiv.org/abs/2001.06988v1)|2020-01-20 05:56:32+00:00|20-01-2020

## 17-01-2020

main_author|title|update_date|publish_date
---|---|---|---
Ulli Waltinger|[AAAI FSS-19: Human-Centered AI: Trustworthiness of AI Models and Data   Proceedings](http://arxiv.org/abs/2001.05375v1)|2020-01-15 15:30:29+00:00|15-01-2020
Chih-Shiang Shur|[Explainable Deep Convolutional Candlestick Learner](http://arxiv.org/abs/2001.02767v3)|2020-01-16 09:09:02+00:00|08-01-2020

## 10-01-2020

main_author|title|update_date|publish_date
---|---|---|---
Shih-Fu Chang|[Bridging Knowledge Graphs to Generate Scene Graphs](http://arxiv.org/abs/2001.02314v1)|2020-01-07 23:35:52+00:00|07-01-2020

## 08-01-2020

main_author|title|update_date|publish_date
---|---|---|---
Volker Tresp|[Reasoning on Knowledge Graphs with Debate Dynamics](http://arxiv.org/abs/2001.00461v1)|2020-01-02 14:44:23+00:00|02-01-2020
Michael Krauthammer|[AutoDiscern: Rating the Quality of Online Health Information with   Hierarchical Encoder Attention-based Neural Networks](http://arxiv.org/abs/1912.12999v1)|2019-12-30 16:44:41+00:00|30-12-2019
Céline Hudelot|[A New Approach for Explainable Multiple Organ Annotation with Few Data](http://arxiv.org/abs/1912.12932v1)|2019-12-30 14:06:32+00:00|30-12-2019
Yunpeng Shi|[Robust Group Synchronization via Cycle-Edge Message Passing](http://arxiv.org/abs/1912.11347v1)|2019-12-24 13:41:00+00:00|24-12-2019
Arno Onken|[Analysis of Video Feature Learning in Two-Stream CNNs on the Example of   Zebrafish Swim Bout Classification](http://arxiv.org/abs/1912.09857v1)|2019-12-20 14:51:35+00:00|20-12-2019

## 13-12-2019

main_author|title|update_date|publish_date
---|---|---|---
Santi Seguí|[WCE Polyp Detection with Triplet based Embeddings](http://arxiv.org/abs/1912.04643v1)|2019-12-10 11:08:45+00:00|10-12-2019
Narges Razavian|[Graph Neural Network on Electronic Health Records for Predicting   Alzheimer's Disease](http://arxiv.org/abs/1912.03761v1)|2019-12-08 21:06:38+00:00|08-12-2019
Suvrit Sra|[Why ADAM Beats SGD for Attention Models](http://arxiv.org/abs/1912.03194v1)|2019-12-06 15:58:29+00:00|06-12-2019
Roman Klinger|[GoodNewsEveryone: A Corpus of News Headlines Annotated with Emotions,   Semantic Roles, and Reader Perception](http://arxiv.org/abs/1912.03184v1)|2019-12-06 15:30:58+00:00|06-12-2019
Eduardo Soares|[Towards Explainable Deep Neural Networks (xDNN)](http://arxiv.org/abs/1912.02523v1)|2019-12-05 12:01:15+00:00|05-12-2019

## 06-12-2019

main_author|title|update_date|publish_date
---|---|---|---
Dan Goldwasser|[An Anomaly Contribution Explainer for Cyber-Security Applications](http://arxiv.org/abs/1912.00314v1)|2019-12-01 04:16:12+00:00|01-12-2019
Changsheng Xu|[Time-Guided High-Order Attention Model of Longitudinal Heterogeneous   Healthcare Data](http://arxiv.org/abs/1912.00773v1)|2019-11-28 03:15:24+00:00|28-11-2019
Aad van Moorsel|[The relationship between trust in AI and trustworthy machine learning   technologies](http://arxiv.org/abs/1912.00782v2)|2019-12-03 11:59:43+00:00|27-11-2019

## 29-11-2019

main_author|title|update_date|publish_date
---|---|---|---
Travis LaCroix|[Biology and Compositionality: Empirical Considerations for   Emergent-Communication Protocols](http://arxiv.org/abs/1911.11668v1)|2019-11-26 16:07:44+00:00|26-11-2019

## 22-11-2019

title|publish_date|main_author
---|---|---
No papers found this week|22-11-2019|  

## 21-11-2019

title|publish_date|main_author
---|---|---
No papers found this week|21-11-2019|  

## 21-11-2019

main_author|title|update_date|publish_date
---|---|---|---
Ehud Reiter|[Natural Language Generation Challenges for Explainable AI](http://arxiv.org/abs/1911.08794v1)|2019-11-20 09:52:23+00:00|20-11-2019
Xiaodan Liang|[Vision-Language Navigation with Self-Supervised Auxiliary Reasoning   Tasks](http://arxiv.org/abs/1911.07883v1)|2019-11-18 19:17:57+00:00|18-11-2019
Maithilee Kunda|[Modeling Gestalt Visual Reasoning on the Raven's Progressive Matrices   Intelligence Test Using Generative Image Inpainting Techniques](http://arxiv.org/abs/1911.07736v1)|2019-11-18 16:16:55+00:00|18-11-2019
Ziyan Wu|[Learning Similarity Attention](http://arxiv.org/abs/1911.07381v1)|2019-11-18 00:46:40+00:00|18-11-2019
Jimeng Sun|[CASTER: Predicting Drug Interactions with Chemical Substructure   Representation](http://arxiv.org/abs/1911.06446v2)|2019-11-20 03:55:01+00:00|15-11-2019
Sambuddha Ghosal|[Deep Generative Models Strike Back! Improving Understanding and   Evaluation in Light of Unmet Expectations for OoD Data](http://arxiv.org/abs/1911.04699v1)|2019-11-12 06:41:22+00:00|12-11-2019
Weisi Guo|[Explainable Artificial Intelligence (XAI) for 6G: Improving Trust   between Human and Machine](http://arxiv.org/abs/1911.04542v2)|2019-11-19 21:37:33+00:00|11-11-2019
M. W. Spratling|[Explaining Away Results in Accurate and Tolerant Template Matching](http://arxiv.org/abs/1911.04169v1)|2019-11-11 10:44:42+00:00|11-11-2019
H. Andrew Schwartz|[Correcting Sociodemographic Selection Biases for Accurate Population   Prediction from Social Media](http://arxiv.org/abs/1911.03855v1)|2019-11-10 05:13:29+00:00|10-11-2019
Xiang Ren|[Towards Hierarchical Importance Attribution: Explaining Compositional   Semantics for Neural Sequence Models](http://arxiv.org/abs/1911.06194v1)|2019-11-08 03:25:04+00:00|08-11-2019
Dongwon Lee|[Why X rather than Y? Explaining Neural Model' Predictions by Generating   Intervention Counterfactual Samples](http://arxiv.org/abs/1911.02042v1)|2019-11-05 19:06:29+00:00|05-11-2019
Wei Fan|[Explaining the Predictions of Any Image Classifier via Decision Trees](http://arxiv.org/abs/1911.01058v1)|2019-11-04 07:31:30+00:00|04-11-2019
Bowen Zhou|[Select, Answer and Explain: Interpretable Multi-hop Reading   Comprehension over Multiple Documents](http://arxiv.org/abs/1911.00484v2)|2019-11-04 01:45:25+00:00|01-11-2019
Stéphane Dupont|[Can adversarial training learn image captioning ?](http://arxiv.org/abs/1910.14609v1)|2019-10-31 16:59:14+00:00|31-10-2019
Isao Echizen|[Use of a Capsule Network to Detect Fake Images and Videos](http://arxiv.org/abs/1910.12467v2)|2019-10-29 14:30:58+00:00|28-10-2019
Walter Karlen|[CXPlain: Causal Explanations for Model Interpretation under Uncertainty](http://arxiv.org/abs/1910.12336v1)|2019-10-27 19:59:18+00:00|27-10-2019
Vishaal Udandarao|[Memeify: A Large-Scale Meme Generation System](http://arxiv.org/abs/1910.12279v1)|2019-10-27 15:13:26+00:00|27-10-2019
Tetusya Takiguchi|[Assisting human experts in the interpretation of their visual process: A   case study on assessing copper surface adhesive potency](http://arxiv.org/abs/1910.11033v1)|2019-10-24 11:23:58+00:00|24-10-2019
Sebastian Lapuschkin|[Towards best practice in explaining neural network decisions with LRP](http://arxiv.org/abs/1910.09840v1)|2019-10-22 08:58:54+00:00|22-10-2019
Pushmeet Kohli|[An Alternative Surrogate Loss for PGD-based Adversarial Testing](http://arxiv.org/abs/1910.09338v1)|2019-10-21 13:08:54+00:00|21-10-2019
Barbara Hammer|[Recovering Localized Adversarial Attacks](http://arxiv.org/abs/1910.09239v1)|2019-10-21 09:53:44+00:00|21-10-2019
Takayuki Okatani|[Analysis and a Solution of Momentarily Missed Detection for Anchor-based   Object Detectors](http://arxiv.org/abs/1910.09212v1)|2019-10-21 08:57:37+00:00|21-10-2019
Xinhong Hei|[A game method for improving the interpretability of convolution neural   network](http://arxiv.org/abs/1910.09090v1)|2019-10-21 00:32:40+00:00|21-10-2019
Alexander Wong|[Do Explanations Reflect Decisions? A Machine-centric Strategy to   Quantify the Performance of Explainability Algorithms](http://arxiv.org/abs/1910.07387v2)|2019-10-29 21:14:22+00:00|16-10-2019
Saurabh Johri|[Counterfactual diagnosis](http://arxiv.org/abs/1910.06772v2)|2019-10-28 23:55:42+00:00|15-10-2019
Colin Rowat|[Asymmetric Shapley values: incorporating causal knowledge into   model-agnostic explainability](http://arxiv.org/abs/1910.06358v1)|2019-10-14 18:08:32+00:00|14-10-2019
Sebastian Gehrmann|[exBERT: A Visual Analysis Tool to Explore Learned Representations in   Transformers Models](http://arxiv.org/abs/1910.05276v1)|2019-10-11 16:10:55+00:00|11-10-2019
Phil Blunsom|[Can I Trust the Explainer? Verifying Post-hoc Explanatory Methods](http://arxiv.org/abs/1910.02065v2)|2019-10-09 14:58:47+00:00|04-10-2019
Gilles Tredan|[The Bouncer Problem: Challenges to Remote Explainability](http://arxiv.org/abs/1910.01432v1)|2019-10-03 12:54:00+00:00|03-10-2019
Ali Mirjalili|[Silas: High Performance, Explainable and Verifiable Machine Learning](http://arxiv.org/abs/1910.01382v1)|2019-10-03 10:17:50+00:00|03-10-2019
Junpei Komiyama|[A Robust Transferable Deep Learning Framework for Cross-sectional   Investment Strategy](http://arxiv.org/abs/1910.01491v1)|2019-10-02 11:02:57+00:00|02-10-2019
Hermann Ney|[When and Why is Document-level Context Useful in Neural Machine   Translation?](http://arxiv.org/abs/1910.00294v1)|2019-10-01 10:40:26+00:00|01-10-2019
María Rodríguez Martínez|[MonoNet: Towards Interpretable Models by Learning Monotonic Features](http://arxiv.org/abs/1909.13611v1)|2019-09-30 12:02:16+00:00|30-09-2019
Jung Hoon Lee|[Library network, a possible path to explainable neural networks](http://arxiv.org/abs/1909.13360v2)|2019-11-12 16:12:46+00:00|29-09-2019
Taiji Suzuki|[Compression based bound for non-compressed network: unified   generalization error analysis of large compressible deep neural network](http://arxiv.org/abs/1909.11274v2)|2019-09-26 05:40:09+00:00|25-09-2019
Mohan Sridharan|[Non-monotonic Logical Reasoning Guiding Deep Learning for Explainable   Visual Question Answering](http://arxiv.org/abs/1909.10650v1)|2019-09-23 23:34:32+00:00|23-09-2019
Miguel Navascues|[Quantum Inflation: A General Approach to Quantum Causal Compatibility](http://arxiv.org/abs/1909.10519v1)|2019-09-23 18:00:00+00:00|23-09-2019
Liang Lin|[Explainable High-order Visual Question Reasoning: A New Benchmark and   Knowledge-routed Network](http://arxiv.org/abs/1909.10128v1)|2019-09-23 02:38:56+00:00|23-09-2019

   